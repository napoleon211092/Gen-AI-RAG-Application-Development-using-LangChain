{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c4c3a2",
   "metadata": {},
   "source": [
    "## Use PromptTemplate to create a template for a string prompt\n",
    "By default, PromptTemplate use Python's str.format syntax for templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93b1ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "#\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, AIMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4812283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd12d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(openai_api_key=api_key,model=\"gpt-3.5-turbo-instruct\",temperature=0.5) #gpt-4-0125-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa7dd2",
   "metadata": {},
   "source": [
    "### A simple string based Prompt formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2231444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "input_variables=['adjective', 'content'] template='Tell me a {adjective} joke about {content}'\n",
      "-----------------\n",
      "Tell me a stupid joke about Vietnamese\n",
      "-----------------\n",
      "\n",
      "\n",
      "Why did the Vietnamese man go to the doctor?\n",
      "\n",
      "Because he was having a pho-king headache!\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a {adjective} joke about {content}\")\n",
    "prompt = prompt_template.format(adjective=\"stupid\",content=\"Vietnamese\")\n",
    "print(\"-----------------\")\n",
    "print(prompt_template)\n",
    "print(\"-----------------\")\n",
    "print(prompt)\n",
    "response = model.invoke(prompt)\n",
    "print(\"-----------------\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066c355",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate: The prompt to chat model is a list of chat message\n",
    "Each chat message is associated with content and an additional parameter called role.\n",
    "\n",
    "For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human, or a system role.\n",
    "\n",
    "(Mỗi tin nhắn trò chuyện được liên kết với nội dung và một tham số bổ sung gọi là vai trò.\n",
    "\n",
    "Ví dụ: trong API hoàn thành trò chuyện OpenAI, tin nhắn trò chuyện có thể được liên kết với trợ lý AI, con người hoặc vai trò hệ thống.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5683c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "input_variables=['name', 'user_input'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful AI bot. Your name is {name}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hello, how are you doing?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"I'm doing well, thanks!\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))]\n",
      "-----------------\n",
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is you name and what are you good at?')]\n",
      "-----------------\n",
      "\n",
      "AI: My name is Bob and I am good at assisting with tasks, providing information, and learning new things. Is there something specific you need help with?\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful AI bot. Your name is {name}\"),\n",
    "        (\"human\",\"Hello, how are you doing?\"),\n",
    "        (\"ai\",\"I'm doing well, thanks!\"),\n",
    "        (\"human\",\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt = chat_template.format_messages(name=\"Bob\",\n",
    "                                       user_input=\"What is you name and what are you good at?\"\n",
    "                                      )\n",
    "print(\"-----------------\")\n",
    "print(chat_template)\n",
    "print(\"-----------------\")\n",
    "print(prompt)\n",
    "response = model.invoke(prompt)\n",
    "print(\"-----------------\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39128d3f",
   "metadata": {},
   "source": [
    "### Various ways of formatting System/Human/AI prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaf364d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "input_variables=['text'] messages=[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more beat\"), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Give an answer in English and then translate the answer to Vietnamese'))]\n",
      "-----------------\n",
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more beat\"), HumanMessage(content=\"I don't like eating tasty things\"), AIMessage(content='Give an answer in English and then translate the answer to Vietnamese')]\n",
      "-----------------\n",
      "\n",
      "\n",
      "I'm not a fan of indulging in delicious treats.\n",
      "Tôi không thích ăn những thứ ngon lành.\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to sound more beat\" # Bạn là một trợ lý hữu ích giúp viết lại văn bản của người dùng để nghe có nhịp điệu hơn\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "        AIMessagePromptTemplate.from_template(\"Give an answer in English and then translate the answer to Vietnamese\")\n",
    "    ]\n",
    ")\n",
    "prompt = chat_template.format_messages(text=\"I don't like eating tasty things\") #Tôi không thích ăn đồ ngon.\n",
    "print(\"-----------------\")\n",
    "print(chat_template)\n",
    "print(\"-----------------\")\n",
    "print(prompt)\n",
    "response = model.invoke(prompt)\n",
    "print(\"-----------------\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d1b7be",
   "metadata": {},
   "source": [
    "### Providing a Context along with the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "380c32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\"\n",
    "# Context: Mô hình ngôn ngữ lớn (LLM) là những mô hình mới nhất được sử dụng trong NLP.\n",
    "# Hiệu suất vượt trội của chúng so với các mô hình nhỏ hơn đã khiến chúng cực kỳ hữu ích cho các nhà phát triển xây dựng các ứng dụng hỗ trợ NLP. \n",
    "# Bạn có thể truy cập các mô hình này thông qua thư viện `transformers` của Hugging Face, qua OpenAI bằng thư viện `openai` và qua Cohere bằng thư viện `cohere`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "830ed209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
