{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc515b0",
   "metadata": {},
   "source": [
    "<b>This program demonstrates a simple usage of creating an LCEL-based chain.</b> <br>\n",
    "→<i>(Chương trình này trình bày cách sử dụng đơn giản để tạo chuỗi dựa trên LCEL.)</i>\n",
    "<br>\n",
    "<b>The chain comprises a prompt, the llm object, and a StringOutput parser.</b> <br>\n",
    "→<i>(Chuỗi bao gồm prompt, đối tượng llm và trình phân tích cú pháp StringOutput.)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e25eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118c381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc02ffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='you are world class technical documentation writer')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are world class technical documentation writer\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b83a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can help with testing in several ways:\n",
      "\n",
      "1. Automated Testing: Langsmith can be integrated with various testing frameworks and tools to automate the testing process. This can help in executing test cases quickly and efficiently, ensuring faster feedback on code changes.\n",
      "\n",
      "2. Test Data Generation: Langsmith can generate test data automatically, which can be used to create comprehensive test scenarios and ensure thorough testing coverage.\n",
      "\n",
      "3. Test Scenario Generation: Langsmith can assist in creating test scenarios based on the requirements and specifications provided. This can help in ensuring that all possible scenarios are covered during testing.\n",
      "\n",
      "4. Regression Testing: Langsmith can be used to automate regression testing, ensuring that new code changes do not break existing functionality.\n",
      "\n",
      "5. Performance Testing: Langsmith can help in simulating a large number of users or requests to test the performance of the system under different load conditions.\n",
      "\n",
      "Overall, Langsmith can streamline the testing process, improve test coverage, and ensure the quality of the software being developed.\n"
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "output = chain.invoke({\"input\":\"how can langsmith help with testing?\"})\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
